{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb8a3db8-28ac-4890-982c-02bbbebdcd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/31 13:46:23 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/31 13:46:24 WARN spark.SparkContext: Please ensure that the number of slots available on your executors is limited by the number of cores to task cpus and not another custom resource. If cores is not the limiting resource then dynamic allocation will not work properly!\n"
     ]
    }
   ],
   "source": [
    "# get spark session, 2g mem per executor\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "# set python env\n",
    "os.environ['PYSPARK_PYTHON'] = \"/opt/conda3/envs/lab2/bin/python\"\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CalculateVetTwitteTFIDF\") \\\n",
    "    .master(\"spark://node01:10077\") \\\n",
    "    .enableHiveSupport()\\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.cores.max\", \"3\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"12\") \\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "111ff9bf-52df-44be-9bfe-e37742f5df81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "date_string = datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d58a550b-da40-4ee8-96ca-68d65ad34507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+------------+---+----+\n",
      "|key_word|item_num_has_word|item_num_all|idf|date|\n",
      "+--------+-----------------+------------+---+----+\n",
      "+--------+-----------------+------------+---+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+\n",
      "|database|           tableName|isTemporary|\n",
      "+--------+--------------------+-----------+\n",
      "| default|cattle_prod_word_...|      false|\n",
      "| default|           event_ods|      false|\n",
      "| default|     item_fresh_list|      false|\n",
      "| default|       item_hot_list|      false|\n",
      "| default|            item_ods|      false|\n",
      "| default|          item_order|      false|\n",
      "| default|          item_score|      false|\n",
      "| default|        item_tag_ods|      false|\n",
      "| default|     item_word_count|      false|\n",
      "| default|       item_word_idf|      false|\n",
      "| default|        item_word_tf|      false|\n",
      "| default|     item_word_tfidf|      false|\n",
      "| default|             tag_ods|      false|\n",
      "| default|                test|      false|\n",
      "| default|               test2|      false|\n",
      "| default|user_item_action_...|      false|\n",
      "| default|            user_ods|      false|\n",
      "| default|        user_tag_ods|      false|\n",
      "| default|vet_twitte_conten...|      false|\n",
      "| default|vet_twitte_title_idf|      false|\n",
      "+--------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute title IDF\n",
    "item_word_idf = spark.sql('''\n",
    "select\n",
    "    key_word,\n",
    "    count(distinct item_id) as item_num_has_word,\n",
    "    max(a.item_num) as item_num_all,\n",
    "    log10(max(a.item_num)/ count(distinct item_id)) as idf,\n",
    "    max(date) as date\n",
    "from\n",
    "    vet_twitte_title_word_count,(\n",
    "        select\n",
    "            count(distinct item_id) as item_num\n",
    "        from\n",
    "            vet_twitte_title_word_count\n",
    "    ) as a\n",
    "group by\n",
    "    key_word\n",
    "order by\n",
    "    idf desc\n",
    "''')\n",
    "item_word_idf.createOrReplaceTempView(\"vet_twitte_title_idf\")\n",
    "item_word_idf.show()\n",
    "item_word_idf.write.mode(\"overwrite\").partitionBy(\"date\").saveAsTable(\"vet_twitte_title_idf\")\n",
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5512640-769c-4f98-9a5b-91b25f38851b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+\n",
      "|database|           tableName|isTemporary|\n",
      "+--------+--------------------+-----------+\n",
      "| default|cattle_prod_word_...|      false|\n",
      "| default|           event_ods|      false|\n",
      "| default|     item_fresh_list|      false|\n",
      "| default|       item_hot_list|      false|\n",
      "| default|            item_ods|      false|\n",
      "| default|          item_order|      false|\n",
      "| default|          item_score|      false|\n",
      "| default|        item_tag_ods|      false|\n",
      "| default|     item_word_count|      false|\n",
      "| default|       item_word_idf|      false|\n",
      "| default|        item_word_tf|      false|\n",
      "| default|     item_word_tfidf|      false|\n",
      "| default|             tag_ods|      false|\n",
      "| default|                test|      false|\n",
      "| default|               test2|      false|\n",
      "| default|user_item_action_...|      false|\n",
      "| default|            user_ods|      false|\n",
      "| default|        user_tag_ods|      false|\n",
      "| default|vet_twitte_conten...|      false|\n",
      "| default|vet_twitte_title_idf|      false|\n",
      "+--------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute title TF\n",
    "item_word_tf = spark.sql(f'''\n",
    "with item_word_total_num as(\n",
    "    select\n",
    "        item_id,\n",
    "        sum(word_count) as word_total\n",
    "    from\n",
    "        vet_twitte_title_word_count\n",
    "    group by\n",
    "        item_id\n",
    "), item_all as(\n",
    "    select\n",
    "        distinct id as item_id\n",
    "    from\n",
    "        item_ods\n",
    "), word_all as(\n",
    "    select\n",
    "        distinct key_word\n",
    "    from\n",
    "        vet_twitte_title_word_count\n",
    "), item_word_all as(\n",
    "    select\n",
    "        item_id,\n",
    "        key_word\n",
    "    from\n",
    "        item_all,\n",
    "        word_all\n",
    ")\n",
    "select \n",
    "    a.item_id,\n",
    "    a.key_word,\n",
    "    if(b.item_id is null or c.word_count is null or b.item_id = 0, 0, c.word_count/b.word_total) as tf,\n",
    "    '{date_string}' as date\n",
    "from\n",
    "    item_word_all a\n",
    "left join\n",
    "    item_word_total_num b on a.item_id = b.item_id\n",
    "left join\n",
    "    vet_twitte_title_word_count c on a.item_id = c.item_id and a.key_word = c.key_word\n",
    "order by\n",
    "    tf desc\n",
    "''')\n",
    "item_word_tf.createOrReplaceGlobalTempView(\"vet_twitte_title_tf\")\n",
    "item_word_tf.write.mode(\"overwrite\").partitionBy(\"date\").saveAsTable(\"vet_twitte_title_tf\")\n",
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a379519-c7ed-4431-9332-11f1a86cc60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------------------+----------+\n",
      "|item_id|key_word|             tfidf|      date|\n",
      "+-------+--------+------------------+----------+\n",
      "|     80|  黑山羊|0.8788292987844551|2023-05-02|\n",
      "|     39|    延边|0.8788292987844551|2023-05-02|\n",
      "|    245|咨询服务|0.8637466566534813|2023-05-02|\n",
      "|    236|    牛类|0.8137711620101613|2023-05-02|\n",
      "|     79|    牛骨|0.7784859668964614|2023-05-02|\n",
      "|     78|    红烧|0.7784859668964614|2023-05-02|\n",
      "|    243|    建设|0.7532822561009616|2023-05-02|\n",
      "|    279|消化不良|0.7532822561009616|2023-05-02|\n",
      "|    242|    乳牛|0.7165559425356435|2023-05-02|\n",
      "|     76|    牛排|0.6781426350084676|2023-05-02|\n",
      "|    225|  抗生素|0.6672736859112526|2023-05-02|\n",
      "|    253|    奶粉|0.6672736859112526|2023-05-02|\n",
      "|    243|    牛棚|0.6672736859112526|2023-05-02|\n",
      "|    280|  胃肠炎|0.6591219740883414|2023-05-02|\n",
      "|    214|    储藏|0.6591219740883414|2023-05-02|\n",
      "|     12|  南犬牛|0.6591219740883414|2023-05-02|\n",
      "|    232|  牛舒安|0.6591219740883414|2023-05-02|\n",
      "|     32|      拉|0.6458392973391155|2023-05-02|\n",
      "|     33|  巴拉巴|0.6458392973391155|2023-05-02|\n",
      "|     35|      拉|0.6458392973391155|2023-05-02|\n",
      "+-------+--------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+\n",
      "|database|           tableName|isTemporary|\n",
      "+--------+--------------------+-----------+\n",
      "| default|cattle_prod_word_...|      false|\n",
      "| default|           event_ods|      false|\n",
      "| default|     item_fresh_list|      false|\n",
      "| default|       item_hot_list|      false|\n",
      "| default|            item_ods|      false|\n",
      "| default|          item_order|      false|\n",
      "| default|          item_score|      false|\n",
      "| default|        item_tag_ods|      false|\n",
      "| default|     item_word_count|      false|\n",
      "| default|       item_word_idf|      false|\n",
      "| default|        item_word_tf|      false|\n",
      "| default|     item_word_tfidf|      false|\n",
      "| default|             tag_ods|      false|\n",
      "| default|                test|      false|\n",
      "| default|               test2|      false|\n",
      "| default|user_item_action_...|      false|\n",
      "| default|            user_ods|      false|\n",
      "| default|        user_tag_ods|      false|\n",
      "| default|vet_twitte_conten...|      false|\n",
      "| default|vet_twitte_title_idf|      false|\n",
      "+--------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute title tf-idf\n",
    "item_word_tfidf = spark.sql('''\n",
    "select \n",
    "    tf.item_id,\n",
    "    tf.key_word,\n",
    "    tf.tf * idf.idf as tfidf,\n",
    "    tf.date\n",
    "from\n",
    "    item_word_tf as tf\n",
    "left join\n",
    "    item_word_idf as idf on idf.key_word = tf.key_word\n",
    "order by\n",
    "    tfidf desc\n",
    "''')\n",
    "item_word_tfidf.createOrReplaceGlobalTempView(\"vet_twitte_title_tfidf\")\n",
    "item_word_tfidf.show()\n",
    "item_word_tfidf.write.mode(\"overwrite\").saveAsTable(\"vet_twitte_title_tfidf\")\n",
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07806460-85c1-4b68-8fe7-94f536881f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+------------+---+----+\n",
      "|key_word|item_num_has_word|item_num_all|idf|date|\n",
      "+--------+-----------------+------------+---+----+\n",
      "+--------+-----------------+------------+---+----+\n",
      "\n",
      "+--------+--------------------+-----------+\n",
      "|database|           tableName|isTemporary|\n",
      "+--------+--------------------+-----------+\n",
      "| default|     cattle_prod_idf|      false|\n",
      "| default|cattle_prod_word_...|      false|\n",
      "| default|           event_ods|      false|\n",
      "| default|     item_fresh_list|      false|\n",
      "| default|       item_hot_list|      false|\n",
      "| default|            item_ods|      false|\n",
      "| default|          item_order|      false|\n",
      "| default|          item_score|      false|\n",
      "| default|        item_tag_ods|      false|\n",
      "| default|     item_word_count|      false|\n",
      "| default|       item_word_idf|      false|\n",
      "| default|        item_word_tf|      false|\n",
      "| default|     item_word_tfidf|      false|\n",
      "| default|             tag_ods|      false|\n",
      "| default|                test|      false|\n",
      "| default|               test2|      false|\n",
      "| default|user_item_action_...|      false|\n",
      "| default|            user_ods|      false|\n",
      "| default|        user_tag_ods|      false|\n",
      "| default|vet_twitte_conten...|      false|\n",
      "+--------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute content IDF\n",
    "item_word_idf = spark.sql('''\n",
    "select\n",
    "    key_word,\n",
    "    count(distinct item_id) as item_num_has_word,\n",
    "    max(a.item_num) as item_num_all,\n",
    "    log10(max(a.item_num)/ count(distinct item_id)) as idf,\n",
    "    max(date) as date\n",
    "from\n",
    "    vet_twitte_content_word_count,(\n",
    "        select\n",
    "            count(distinct item_id) as item_num\n",
    "        from\n",
    "            vet_twitte_content_word_count\n",
    "    ) as a\n",
    "group by\n",
    "    key_word\n",
    "order by\n",
    "    idf desc\n",
    "''')\n",
    "item_word_idf.createOrReplaceTempView(\"vet_twitte_content_idf\")\n",
    "item_word_idf.show()\n",
    "item_word_idf.write.mode(\"overwrite\").partitionBy(\"date\").saveAsTable(\"vet_twitte_content_idf\")\n",
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eba3425c-d4a3-44c4-b1e0-cfcedb7c0f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+\n",
      "|database|           tableName|isTemporary|\n",
      "+--------+--------------------+-----------+\n",
      "| default|     cattle_prod_idf|      false|\n",
      "| default|      cattle_prod_tf|      false|\n",
      "| default|cattle_prod_word_...|      false|\n",
      "| default|           event_ods|      false|\n",
      "| default|     item_fresh_list|      false|\n",
      "| default|       item_hot_list|      false|\n",
      "| default|            item_ods|      false|\n",
      "| default|          item_order|      false|\n",
      "| default|          item_score|      false|\n",
      "| default|        item_tag_ods|      false|\n",
      "| default|     item_word_count|      false|\n",
      "| default|       item_word_idf|      false|\n",
      "| default|        item_word_tf|      false|\n",
      "| default|     item_word_tfidf|      false|\n",
      "| default|             tag_ods|      false|\n",
      "| default|                test|      false|\n",
      "| default|               test2|      false|\n",
      "| default|user_item_action_...|      false|\n",
      "| default|            user_ods|      false|\n",
      "| default|        user_tag_ods|      false|\n",
      "+--------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute content TF\n",
    "item_word_tf = spark.sql(f'''\n",
    "with item_word_total_num as(\n",
    "    select\n",
    "        item_id,\n",
    "        sum(word_count) as word_total\n",
    "    from\n",
    "        vet_twitte_content_word_count\n",
    "    group by\n",
    "        item_id\n",
    "), item_all as(\n",
    "    select\n",
    "        distinct id as item_id\n",
    "    from\n",
    "        item_ods\n",
    "), word_all as(\n",
    "    select\n",
    "        distinct key_word\n",
    "    from\n",
    "        vet_twitte_content_word_count\n",
    "), item_word_all as(\n",
    "    select\n",
    "        item_id,\n",
    "        key_word\n",
    "    from\n",
    "        item_all,\n",
    "        word_all\n",
    ")\n",
    "select \n",
    "    a.item_id,\n",
    "    a.key_word,\n",
    "    if(b.item_id is null or c.word_count is null or b.item_id = 0, 0, c.word_count/b.word_total) as tf,\n",
    "    '{date_string}' as date\n",
    "from\n",
    "    item_word_all a\n",
    "left join\n",
    "    item_word_total_num b on a.item_id = b.item_id\n",
    "left join\n",
    "    vet_twitte_content_word_count c on a.item_id = c.item_id and a.key_word = c.key_word\n",
    "order by\n",
    "    tf desc\n",
    "''')\n",
    "item_word_tf.createOrReplaceGlobalTempView(\"vet_twitte_content_tf\")\n",
    "item_word_tf.write.mode(\"overwrite\").partitionBy(\"date\").saveAsTable(\"vet_twitte_content_tf\")\n",
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cdfe085-b2d2-414c-bfe4-ca39d33afb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------------------+----------+\n",
      "|item_id|key_word|             tfidf|      date|\n",
      "+-------+--------+------------------+----------+\n",
      "|     80|  黑山羊|0.8788292987844551|2023-05-02|\n",
      "|     39|    延边|0.8788292987844551|2023-05-02|\n",
      "|    245|咨询服务|0.8637466566534813|2023-05-02|\n",
      "|    236|    牛类|0.8137711620101613|2023-05-02|\n",
      "|     79|    牛骨|0.7784859668964614|2023-05-02|\n",
      "|     78|    红烧|0.7784859668964614|2023-05-02|\n",
      "|    243|    建设|0.7532822561009616|2023-05-02|\n",
      "|    279|消化不良|0.7532822561009616|2023-05-02|\n",
      "|    242|    乳牛|0.7165559425356435|2023-05-02|\n",
      "|     76|    牛排|0.6781426350084676|2023-05-02|\n",
      "|    225|  抗生素|0.6672736859112526|2023-05-02|\n",
      "|    253|    奶粉|0.6672736859112526|2023-05-02|\n",
      "|    243|    牛棚|0.6672736859112526|2023-05-02|\n",
      "|    280|  胃肠炎|0.6591219740883414|2023-05-02|\n",
      "|    214|    储藏|0.6591219740883414|2023-05-02|\n",
      "|     12|  南犬牛|0.6591219740883414|2023-05-02|\n",
      "|    232|  牛舒安|0.6591219740883414|2023-05-02|\n",
      "|     32|      拉|0.6458392973391155|2023-05-02|\n",
      "|     33|  巴拉巴|0.6458392973391155|2023-05-02|\n",
      "|     35|      拉|0.6458392973391155|2023-05-02|\n",
      "+-------+--------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+\n",
      "|database|           tableName|isTemporary|\n",
      "+--------+--------------------+-----------+\n",
      "| default|     cattle_prod_idf|      false|\n",
      "| default|      cattle_prod_tf|      false|\n",
      "| default|cattle_prod_word_...|      false|\n",
      "| default|           event_ods|      false|\n",
      "| default|     item_fresh_list|      false|\n",
      "| default|       item_hot_list|      false|\n",
      "| default|            item_ods|      false|\n",
      "| default|          item_order|      false|\n",
      "| default|          item_score|      false|\n",
      "| default|        item_tag_ods|      false|\n",
      "| default|     item_word_count|      false|\n",
      "| default|       item_word_idf|      false|\n",
      "| default|        item_word_tf|      false|\n",
      "| default|     item_word_tfidf|      false|\n",
      "| default|             tag_ods|      false|\n",
      "| default|                test|      false|\n",
      "| default|               test2|      false|\n",
      "| default|user_item_action_...|      false|\n",
      "| default|            user_ods|      false|\n",
      "| default|        user_tag_ods|      false|\n",
      "+--------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute content tf-idf\n",
    "item_word_tfidf = spark.sql('''\n",
    "select \n",
    "    tf.item_id,\n",
    "    tf.key_word,\n",
    "    tf.tf * idf.idf as tfidf,\n",
    "    tf.date\n",
    "from\n",
    "    item_word_tf as tf\n",
    "left join\n",
    "    item_word_idf as idf on idf.key_word = tf.key_word\n",
    "order by\n",
    "    tfidf desc\n",
    "''')\n",
    "item_word_tfidf.createOrReplaceGlobalTempView(\"vet_twitte_content_tfidf\")\n",
    "item_word_tfidf.show()\n",
    "item_word_tfidf.write.mode(\"overwrite\").saveAsTable(\"vet_twitte_content_tfidf\")\n",
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98bedf03-becd-409e-b062-b16b20f7c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9573b4e8-e223-48af-a7c6-8176cec32a27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
