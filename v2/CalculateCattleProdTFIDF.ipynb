{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c48bcb6-8e26-46f0-a149-776e149df139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/31 13:50:12 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/31 13:50:13 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/05/31 13:50:13 WARN spark.SparkContext: Please ensure that the number of slots available on your executors is limited by the number of cores to task cpus and not another custom resource. If cores is not the limiting resource then dynamic allocation will not work properly!\n"
     ]
    }
   ],
   "source": [
    "# get spark session, 2g mem per executor\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "# set python env\n",
    "os.environ['PYSPARK_PYTHON'] = \"/opt/conda3/envs/lab2/bin/python\"\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CalculateCattleProdTFIDF\") \\\n",
    "    .master(\"spark://node01:10077\") \\\n",
    "    .enableHiveSupport()\\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.cores.max\", \"3\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"12\") \\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fece606f-ca80-441c-854a-fd51e6c17b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "date_string = datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49cf726b-e8b2-4262-ad53-0d0a60110490",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/31 13:50:30 WARN session.SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+------------+------------------+----------+\n",
      "|key_word|item_num_has_word|item_num_all|               idf|      date|\n",
      "+--------+-----------------+------------+------------------+----------+\n",
      "|    400g|                1|         112|2.0492180226701815|2023-05-31|\n",
      "|    不二|                1|         112|2.0492180226701815|2023-05-31|\n",
      "|  中草药|                1|         112|2.0492180226701815|2023-05-31|\n",
      "|    之选|                1|         112|2.0492180226701815|2023-05-31|\n",
      "|    乳酪|                1|         112|2.0492180226701815|2023-05-31|\n",
      "|    低温|                1|         112|2.0492180226701815|2023-05-31|\n",
      "|    回味|                1|         112|2.0492180226701815|2023-05-31|\n",
      "|    尽享|                1|         112|2.0492180226701815|2023-05-31|\n",
      "|    悠长|                1|         112|2.0492180226701815|2023-05-31|\n",
      "|    户外|                1|         112|2.0492180226701815|2023-05-31|\n",
      "|    牛腿|                1|         112|2.0492180226701815|2023-05-31|\n",
      "|    生于|                1|         112|2.0492180226701815|2023-05-31|\n",
      "|    红润|                1|         112|2.0492180226701815|2023-05-31|\n",
      "|    红烧|                1|         112|2.0492180226701815|2023-05-31|\n",
      "|      肥|                1|         112|2.0492180226701815|2023-05-31|\n",
      "|    肥而|                1|         112|2.0492180226701815|2023-05-31|\n",
      "|    饺子|                1|         112|2.0492180226701815|2023-05-31|\n",
      "|      香|                1|         112|2.0492180226701815|2023-05-31|\n",
      "|      骨|                1|         112|2.0492180226701815|2023-05-31|\n",
      "|      鲜|                1|         112|2.0492180226701815|2023-05-31|\n",
      "+--------+-----------------+------------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+\n",
      "|database|           tableName|isTemporary|\n",
      "+--------+--------------------+-----------+\n",
      "| default|     cattle_prod_idf|      false|\n",
      "| default|cattle_prod_word_...|      false|\n",
      "| default|           event_ods|      false|\n",
      "| default|     item_fresh_list|      false|\n",
      "| default|       item_hot_list|      false|\n",
      "| default|            item_ods|      false|\n",
      "| default|          item_order|      false|\n",
      "| default|          item_score|      false|\n",
      "| default|        item_tag_ods|      false|\n",
      "| default|     item_word_count|      false|\n",
      "| default|       item_word_idf|      false|\n",
      "| default|        item_word_tf|      false|\n",
      "| default|     item_word_tfidf|      false|\n",
      "| default|             tag_ods|      false|\n",
      "| default|                test|      false|\n",
      "| default|               test2|      false|\n",
      "| default|user_item_action_...|      false|\n",
      "| default|            user_ods|      false|\n",
      "| default|        user_tag_ods|      false|\n",
      "| default|vet_twitte_conten...|      false|\n",
      "+--------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute IDF\n",
    "item_word_idf = spark.sql('''\n",
    "select\n",
    "    key_word,\n",
    "    count(distinct item_id) as item_num_has_word,\n",
    "    max(a.item_num) as item_num_all,\n",
    "    log10(max(a.item_num)/ count(distinct item_id)) as idf,\n",
    "    max(date) as date\n",
    "from\n",
    "    cattle_prod_word_count,(\n",
    "        select\n",
    "            count(distinct item_id) as item_num\n",
    "        from\n",
    "            cattle_prod_word_count\n",
    "    ) as a\n",
    "group by\n",
    "    key_word\n",
    "order by\n",
    "    idf desc\n",
    "''')\n",
    "item_word_idf.createOrReplaceTempView(\"cattle_prod_idf\")\n",
    "item_word_idf.show()\n",
    "item_word_idf.write.mode(\"overwrite\").partitionBy(\"date\").saveAsTable(\"cattle_prod_idf\")\n",
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba979014-9319-4c19-a932-729064a51693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+\n",
      "|database|           tableName|isTemporary|\n",
      "+--------+--------------------+-----------+\n",
      "| default|     cattle_prod_idf|      false|\n",
      "| default|      cattle_prod_tf|      false|\n",
      "| default|cattle_prod_word_...|      false|\n",
      "| default|           event_ods|      false|\n",
      "| default|     item_fresh_list|      false|\n",
      "| default|       item_hot_list|      false|\n",
      "| default|            item_ods|      false|\n",
      "| default|          item_order|      false|\n",
      "| default|          item_score|      false|\n",
      "| default|        item_tag_ods|      false|\n",
      "| default|     item_word_count|      false|\n",
      "| default|       item_word_idf|      false|\n",
      "| default|        item_word_tf|      false|\n",
      "| default|     item_word_tfidf|      false|\n",
      "| default|             tag_ods|      false|\n",
      "| default|                test|      false|\n",
      "| default|               test2|      false|\n",
      "| default|user_item_action_...|      false|\n",
      "| default|            user_ods|      false|\n",
      "| default|        user_tag_ods|      false|\n",
      "+--------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute TF\n",
    "item_word_tf = spark.sql(f'''\n",
    "with item_word_total_num as(\n",
    "    select\n",
    "        item_id,\n",
    "        sum(word_count) as word_total\n",
    "    from\n",
    "        cattle_prod_word_count\n",
    "    group by\n",
    "        item_id\n",
    "), item_all as(\n",
    "    select\n",
    "        distinct id as item_id\n",
    "    from\n",
    "        item_ods\n",
    "), word_all as(\n",
    "    select\n",
    "        distinct key_word\n",
    "    from\n",
    "        cattle_prod_word_count\n",
    "), item_word_all as(\n",
    "    select\n",
    "        item_id,\n",
    "        key_word\n",
    "    from\n",
    "        item_all,\n",
    "        word_all\n",
    ")\n",
    "select \n",
    "    a.item_id,\n",
    "    a.key_word,\n",
    "    if(b.item_id is null or c.word_count is null or b.item_id = 0, 0, c.word_count/b.word_total) as tf,\n",
    "    '{date_string}' as date\n",
    "from\n",
    "    item_word_all a\n",
    "left join\n",
    "    item_word_total_num b on a.item_id = b.item_id\n",
    "left join\n",
    "    cattle_prod_word_count c on a.item_id = c.item_id and a.key_word = c.key_word\n",
    "order by\n",
    "    tf desc\n",
    "''')\n",
    "item_word_tf.createOrReplaceGlobalTempView(\"cattle_prod_tf\")\n",
    "item_word_tf.write.mode(\"overwrite\").partitionBy(\"date\").saveAsTable(\"cattle_prod_tf\")\n",
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e939eeae-f020-4046-b2d8-2c297049137e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------------------+----------+\n",
      "|item_id|key_word|             tfidf|      date|\n",
      "+-------+--------+------------------+----------+\n",
      "|     80|  黑山羊|0.8788292987844551|2023-05-02|\n",
      "|     39|    延边|0.8788292987844551|2023-05-02|\n",
      "|    245|咨询服务|0.8637466566534813|2023-05-02|\n",
      "|    236|    牛类|0.8137711620101613|2023-05-02|\n",
      "|     79|    牛骨|0.7784859668964614|2023-05-02|\n",
      "|     78|    红烧|0.7784859668964614|2023-05-02|\n",
      "|    243|    建设|0.7532822561009616|2023-05-02|\n",
      "|    279|消化不良|0.7532822561009616|2023-05-02|\n",
      "|    242|    乳牛|0.7165559425356435|2023-05-02|\n",
      "|     76|    牛排|0.6781426350084676|2023-05-02|\n",
      "|    225|  抗生素|0.6672736859112526|2023-05-02|\n",
      "|    253|    奶粉|0.6672736859112526|2023-05-02|\n",
      "|    243|    牛棚|0.6672736859112526|2023-05-02|\n",
      "|    280|  胃肠炎|0.6591219740883414|2023-05-02|\n",
      "|    214|    储藏|0.6591219740883414|2023-05-02|\n",
      "|     12|  南犬牛|0.6591219740883414|2023-05-02|\n",
      "|    232|  牛舒安|0.6591219740883414|2023-05-02|\n",
      "|     32|      拉|0.6458392973391155|2023-05-02|\n",
      "|     33|  巴拉巴|0.6458392973391155|2023-05-02|\n",
      "|     35|      拉|0.6458392973391155|2023-05-02|\n",
      "+-------+--------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+\n",
      "|database|           tableName|isTemporary|\n",
      "+--------+--------------------+-----------+\n",
      "| default|     cattle_prod_idf|      false|\n",
      "| default|      cattle_prod_tf|      false|\n",
      "| default|   cattle_prod_tfidf|      false|\n",
      "| default|cattle_prod_word_...|      false|\n",
      "| default|           event_ods|      false|\n",
      "| default|     item_fresh_list|      false|\n",
      "| default|       item_hot_list|      false|\n",
      "| default|            item_ods|      false|\n",
      "| default|          item_order|      false|\n",
      "| default|          item_score|      false|\n",
      "| default|        item_tag_ods|      false|\n",
      "| default|     item_word_count|      false|\n",
      "| default|       item_word_idf|      false|\n",
      "| default|        item_word_tf|      false|\n",
      "| default|     item_word_tfidf|      false|\n",
      "| default|             tag_ods|      false|\n",
      "| default|                test|      false|\n",
      "| default|               test2|      false|\n",
      "| default|user_item_action_...|      false|\n",
      "| default|            user_ods|      false|\n",
      "+--------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute tf-idf\n",
    "item_word_tfidf = spark.sql('''\n",
    "select \n",
    "    tf.item_id,\n",
    "    tf.key_word,\n",
    "    tf.tf * idf.idf as tfidf,\n",
    "    tf.date\n",
    "from\n",
    "    item_word_tf as tf\n",
    "left join\n",
    "    item_word_idf as idf on idf.key_word = tf.key_word\n",
    "order by\n",
    "    tfidf desc\n",
    "''')\n",
    "item_word_tfidf.createOrReplaceGlobalTempView(\"cattle_prod_tfidf\")\n",
    "item_word_tfidf.show()\n",
    "item_word_tfidf.write.mode(\"overwrite\").saveAsTable(\"cattle_prod_tfidf\")\n",
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0f5d3cb-d573-49fd-b2e7-f2c6f295d8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
