{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc05c016-b5ae-4cc9-9355-e8a19664be3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mysql connection\n",
    "import mysql.connector\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"cowstudio.wayne-lee.cn\",\n",
    "  user=\"cowstudio\",\n",
    "  password=\"cowstudio_2119\",\n",
    "  database=\"cowstudio\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0810c0c8-6d01-4965-9f86-4a6bae0fc2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/22 08:20:17 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/04/22 08:20:19 WARN spark.SparkContext: Please ensure that the number of slots available on your executors is limited by the number of cores to task cpus and not another custom resource. If cores is not the limiting resource then dynamic allocation will not work properly!\n"
     ]
    }
   ],
   "source": [
    "# get spark session, 2g mem per executor\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "# set python env\n",
    "os.environ['PYSPARK_PYTHON'] = \"/opt/conda3/envs/lab2/bin/python\"\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"item_order_list\") \\\n",
    "    .master(\"spark://node01:10077\") \\\n",
    "    .enableHiveSupport()\\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.cores.max\", \"3\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"12\") \\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cac3130-b0e4-4218-ba84-a348c3929ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-22\n"
     ]
    }
   ],
   "source": [
    "# define map functions \n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "today_string = datetime.today().strftime('%Y-%m-%d')\n",
    "print(today_string)\n",
    "\n",
    "fresh_list_thr = 10\n",
    "host_list_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bcdac81-67c7-490d-8dd4-8db7963d588c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                  (0 + 2) / 2][Stage 1:=========>         (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+-----+---+\n",
      "|item_id|       category|score| rn|\n",
      "+-------+---------------+-----+---+\n",
      "|    455|service_product| 35.0|  1|\n",
      "|    198|       breeding| 14.0|  1|\n",
      "|    461|        service| 34.0|  1|\n",
      "|     95| cattle_product| 68.0|  1|\n",
      "|    364|   whole_cattle| 34.0|  1|\n",
      "|    232|service_product| 20.0|  2|\n",
      "|    191|       breeding| 10.0|  2|\n",
      "|    359|   whole_cattle| 25.0|  2|\n",
      "|     77| cattle_product| 37.0|  2|\n",
      "|    449|        service| 34.0|  2|\n",
      "|    121|   whole_cattle|  7.0|  3|\n",
      "|    197|       breeding| 10.0|  3|\n",
      "|    454|        service| 21.0|  3|\n",
      "|    221|service_product| 20.0|  3|\n",
      "|     78| cattle_product| 32.0|  3|\n",
      "|    457|        service| 20.0|  4|\n",
      "|    212|service_product| 16.0|  4|\n",
      "|    203|       breeding|  8.0|  4|\n",
      "|    343| cattle_product| 30.0|  4|\n",
      "|    355|   whole_cattle|  7.0|  4|\n",
      "+-------+---------------+-----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "item_order = spark.sql(f'''\n",
    "with item_all as(\n",
    "    select\n",
    "        id as item_id,\n",
    "        category\n",
    "    from\n",
    "        item_ods\n",
    ")\n",
    "select\n",
    "    item_all.item_id,\n",
    "    item_all.category,\n",
    "    item_score.score,\n",
    "    row_number() over(\n",
    "        partition by\n",
    "            category\n",
    "        order by\n",
    "            score desc\n",
    "    ) as rn\n",
    "from\n",
    "    item_all\n",
    "left join\n",
    "    item_score on item_all.item_id = item_score.item_id\n",
    "where\n",
    "    date = '{today_string}'\n",
    "order by\n",
    "    rn\n",
    "''')\n",
    "item_order.show()\n",
    "item_order.createOrReplaceTempView(\"item_order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fc391f4-886a-4b9b-b8f7-41fbc534c59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+-----+---+\n",
      "|item_id|       category|score| rn|\n",
      "+-------+---------------+-----+---+\n",
      "|    121|   whole_cattle|  7.0|  3|\n",
      "|    355|   whole_cattle|  7.0|  4|\n",
      "|    203|       breeding|  8.0|  4|\n",
      "|    196|       breeding|  8.0|  5|\n",
      "|    361|   whole_cattle|  7.0|  5|\n",
      "|    403|   whole_cattle|  6.0|  6|\n",
      "|    452|        service|  4.0|  6|\n",
      "|    194|       breeding|  5.0|  6|\n",
      "|    223|service_product|  8.0|  6|\n",
      "|    372|       breeding|  4.0|  7|\n",
      "|    257|service_product|  8.0|  7|\n",
      "|    389|        service|  4.0|  7|\n",
      "|    414|   whole_cattle|  5.0|  7|\n",
      "|    456|        service|  4.0|  8|\n",
      "|    220|service_product|  6.0|  8|\n",
      "|    127|   whole_cattle|  4.0|  8|\n",
      "|    195|       breeding|  2.0|  8|\n",
      "|    298|        service|  2.0|  9|\n",
      "|    230|service_product|  5.0|  9|\n",
      "|    193|       breeding|  2.0|  9|\n",
      "+-------+---------------+-----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "item_fresh_list = spark.sql(f'''\n",
    "select\n",
    "    *\n",
    "from\n",
    "    item_order\n",
    "where\n",
    "    score < {fresh_list_thr}\n",
    "''')\n",
    "item_fresh_list.show()\n",
    "item_fresh_list.createOrReplaceTempView(\"item_fresh_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ea759a1-3829-4b68-a9ac-ce8657867843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+-----+---+\n",
      "|item_id|       category|score| rn|\n",
      "+-------+---------------+-----+---+\n",
      "|    232|service_product| 20.0|  2|\n",
      "|    343| cattle_product| 30.0|  4|\n",
      "|    461|        service| 34.0|  1|\n",
      "|     77| cattle_product| 37.0|  2|\n",
      "|    191|       breeding| 10.0|  2|\n",
      "|    197|       breeding| 10.0|  3|\n",
      "|     41| cattle_product| 20.0|  8|\n",
      "|     80| cattle_product| 13.0|  9|\n",
      "|     87| cattle_product| 12.0| 11|\n",
      "|    359|   whole_cattle| 25.0|  2|\n",
      "|    449|        service| 34.0|  2|\n",
      "|     83| cattle_product| 10.0| 13|\n",
      "|    198|       breeding| 14.0|  1|\n",
      "|    221|service_product| 20.0|  3|\n",
      "|    455|service_product| 35.0|  1|\n",
      "|    457|        service| 20.0|  4|\n",
      "|     81| cattle_product| 11.0| 12|\n",
      "|    212|service_product| 16.0|  4|\n",
      "|    228|service_product| 15.0|  5|\n",
      "|    364|   whole_cattle| 34.0|  1|\n",
      "+-------+---------------+-----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "item_hot_list = spark.sql(f'''\n",
    "select\n",
    "    a.*\n",
    "from\n",
    "    item_order a\n",
    "left join\n",
    "    item_fresh_list b on a.item_id = b.item_id \n",
    "where\n",
    "    a.rn <= {host_list_size}\n",
    "and\n",
    "    b.item_id is null\n",
    "''')\n",
    "item_hot_list.show()\n",
    "item_hot_list.createOrReplaceTempView(\"item_hot_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6bc9459-c0ce-4e84-87b5-01fbc2f32ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"drop table if exists \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fe5f2f5-6b2f-4c59-82cb-8a4ab58faba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_hot_list.write.mode(\"overwrite\").partitionBy(\"date\").s.partitionBy(\"date\")aveAsTable(\"item_hot_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de3ce11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_hot_list.write.mode(\"overwrite\").partitionBy(\"date\").s.partitionBy(\"date\")aveAsTable(\"item_hot_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3d5231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_hot_list.write.mode(\"overwrite\").partitionBy(\"date\").s.partitionBy(\"date\")aveAsTable(\"item_hot_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42b66a82-f3d6-4321-8ff1-3432002c1439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+-----------+\n",
      "|database|      tableName|isTemporary|\n",
      "+--------+---------------+-----------+\n",
      "| default|      event_ods|      false|\n",
      "| default|item_fresh_list|      false|\n",
      "| default|  item_hot_list|      false|\n",
      "| default|       item_ods|      false|\n",
      "| default|     item_order|      false|\n",
      "| default|     item_score|      false|\n",
      "| default|   item_tag_ods|      false|\n",
      "| default|item_word_count|      false|\n",
      "| default|  item_word_idf|      false|\n",
      "| default|   item_word_tf|      false|\n",
      "| default|item_word_tfidf|      false|\n",
      "| default|        tag_ods|      false|\n",
      "| default|           test|      false|\n",
      "| default|          test2|      false|\n",
      "| default|       user_ods|      false|\n",
      "| default|   user_tag_ods|      false|\n",
      "|        |item_fresh_list|       true|\n",
      "|        |  item_hot_list|       true|\n",
      "|        |     item_order|       true|\n",
      "+--------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff864d83-3ec9-44d0-81c4-02396febd810",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "mydb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f0687-e698-4d75-97cc-7a4d0b9e43b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
