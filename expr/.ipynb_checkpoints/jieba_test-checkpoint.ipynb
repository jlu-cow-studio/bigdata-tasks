{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ff7131a-dd59-41e9-98ef-1712a69ae1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"cowstudio.wayne-lee.cn\",\n",
    "  user=\"cowstudio\",\n",
    "  password=\"cowstudio_2119\",\n",
    "  database=\"cowstudio\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52507062-6d55-4727-b23a-7899e27c317c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/18 10:13:15 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/04/18 10:13:16 WARN spark.SparkContext: Please ensure that the number of slots available on your executors is limited by the number of cores to task cpus and not another custom resource. If cores is not the limiting resource then dynamic allocation will not work properly!\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "os.environ['PYSPARK_PYTHON'] = \"/opt/conda3/envs/lab2/bin/python\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"jieba_test2\") \\\n",
    "    .master(\"spark://node01:10077\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.cores.max\", \"3\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"12\") \\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96b9ae2d-906d-46ec-bf37-6cdf226478e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import jieba.analyse\n",
    "\n",
    "stop_words_rdd = sc.textFile(\"hdfs:///user/spark_temp/stopwords.dat\")\n",
    "stop_words_set = set(stop_words_rdd.collect())\n",
    "\n",
    "def cut_name_and_desc(item):\n",
    "    id, name, desc = item\n",
    "    name_cut = set(jieba.cut(name))\n",
    "    name_cut_pure = set(jieba.cut(name)) - stop_words_set\n",
    "    desc_cut = set(jieba.cut(desc))\n",
    "    desc_cut_pure = set(jieba.cut(desc)) - stop_words_set\n",
    "    return (id,name_cut,name_cut_pure,desc_cut,desc_cut_pure)\n",
    "\n",
    "def to_count(item):\n",
    "    id,name_cut,name_cut_pure,desc_cut,desc_cut_pure = item\n",
    "    for i in name_cut_pure:\n",
    "        yield ((id, i),1)\n",
    "    for i in desc_cut_pure:\n",
    "        yield (i,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc30e905-5271-49bc-a93f-545cb6c70720",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = mydb.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2afea1a-ca44-4e08-bb40-f231478cebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.reset()\n",
    "cur.execute(\"SELECT id,name,description from items order by RAND() \")\n",
    "result = cur.fetchall()\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "567c04d7-9846-405c-8687-d7f579bc1ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_items_rdd = sc.parallelize(result)\n",
    "# print(all_items_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49265f4a-414e-4c34-be50-bf90b1793a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "items_cut_rdd = all_items_rdd.map(cut_name_and_desc)\n",
    "# print(rdd2.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8feaf40d-67be-4431-b8c9-8238992e32c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(item):\n",
    "    aa,c = item\n",
    "    a,b = aa\n",
    "    return a,b,c\n",
    "word_count = items_cut_rdd.flatMap(to_count).reduceByKey(lambda a,b:a+b).map(f1)\n",
    "# print(word_count.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eea56d17-b5b9-4a31-827e-05a2e3267a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+----------+\n",
      "|item_id|key_word|word_count|\n",
      "+-------+--------+----------+\n",
      "|    319|    农庄|         1|\n",
      "|    458|    喂养|         1|\n",
      "|    181|      牛|         1|\n",
      "|    198|      花|         1|\n",
      "|    454|    岗牛|         1|\n",
      "|    454|  黑白花|         1|\n",
      "|    454|    喂养|         1|\n",
      "|    454|    管理|         1|\n",
      "|    218|      牛|         1|\n",
      "|    218|      药|         1|\n",
      "|    180|    母牛|         1|\n",
      "|    253|      牛|         1|\n",
      "|    262|      牛|         1|\n",
      "|    262|    用药|         1|\n",
      "|    370|    肉牛|         1|\n",
      "|     85|    优质|         1|\n",
      "|    417|    一号|         1|\n",
      "|    355|    优质|         1|\n",
      "|    132|    出售|         1|\n",
      "|    132|    红牛|         1|\n",
      "+-------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "schema = StructType([\n",
    "    StructField(\"item_id\", IntegerType(), True),\n",
    "    StructField(\"key_word\", StringType(), True),\n",
    "    StructField(\"word_count\", IntegerType(), True)\n",
    "])\n",
    "df1 = spark.createDataFrame(word_count, schema)\n",
    "df1.createOrReplaceTempView(\"word_count\")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "176d149d-30b6-4622-8513-ae08dd3aa168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+----------+\n",
      "|item_id|key_word|word_count|\n",
      "+-------+--------+----------+\n",
      "|    445|    种苗|         1|\n",
      "|     57|    特产|         1|\n",
      "|    173|    配种|         1|\n",
      "|    449|    岗牛|         1|\n",
      "|     11|      牛|         1|\n",
      "|    228|  驱虫剂|         1|\n",
      "|    358|    肉牛|         1|\n",
      "|    463|    岗牛|         1|\n",
      "|    190|    配种|         1|\n",
      "|    396|  黑白花|         1|\n",
      "|    145|  黑白花|         1|\n",
      "|     40|  牛肉干|         1|\n",
      "|     96|    500g|         1|\n",
      "|    210|荷斯坦种|         1|\n",
      "|    454|    二号|         1|\n",
      "|    253|    奶粉|         1|\n",
      "|    416|    三号|         1|\n",
      "|     13|      黑|         1|\n",
      "|    209|荷斯坦种|         1|\n",
      "|    130|      牛|         1|\n",
      "+-------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = spark.sql('''\n",
    "    select\n",
    "        item_id,\n",
    "        key_word,\n",
    "        sum(word_count) as word_count\n",
    "    from\n",
    "        word_count\n",
    "    group by \n",
    "        item_id ,key_word\n",
    "    order by\n",
    "        word_count desc\n",
    "''')\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb4beed3-be69-4195-b564-0598f2d678d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# spark.sql(\"CREATE TABLE IF NOT EXISTS item_word_count (item_id INT, key_word STRING, word_count INT) USING hive\")\n",
    "# result = spark.sql('''\n",
    "#     insert into table item_word_count select * from word_count\n",
    "# ''')\n",
    "# result.show()\n",
    "df1.write.saveAsTable(\"item_word_count_test\", mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d37f52fb-545a-487e-abc7-39b2fdbb937e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+----------+\n",
      "|item_id|key_word|word_count|\n",
      "+-------+--------+----------+\n",
      "|    446|  黑白花|         1|\n",
      "|     47|    牛油|         1|\n",
      "|     47|      黑|         1|\n",
      "|     47|      焖|         1|\n",
      "|     16|    优质|         1|\n",
      "|     16|     500|         1|\n",
      "|     16|      黑|         1|\n",
      "|     44|  牛肉干|         1|\n",
      "|     44|    食客|         1|\n",
      "|    400|    红牛|         1|\n",
      "|    445|    岗牛|         1|\n",
      "|    445|  黑白花|         1|\n",
      "|    445|    种苗|         1|\n",
      "|    445|    一号|         1|\n",
      "|    445|    供应|         1|\n",
      "|    334|    安置|         1|\n",
      "|     57|    特产|         1|\n",
      "|    390|    指导|         1|\n",
      "|    390|    喂养|         1|\n",
      "|    342|  牛肉干|         1|\n",
      "|    182|      牛|         1|\n",
      "|    182|  荷斯坦|         1|\n",
      "|    113|    东北|         1|\n",
      "|    114|      牛|         1|\n",
      "|    105|    牛蹄|         1|\n",
      "|    164|    黑牛|         1|\n",
      "|    164|    东北|         1|\n",
      "|    283|      牛|         1|\n",
      "|    283|    配种|         1|\n",
      "|     94|    香脆|         1|\n",
      "+-------+--------+----------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351a5acd-61d7-4a1b-8123-934e0d015ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
